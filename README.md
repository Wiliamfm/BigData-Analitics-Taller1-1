# BigData & Analitics-Taller1-1

Integrantes:
William Fonseca
-Moisés Salcedo

## Parte 1:
Instalamos Hadoop en ubuntu

![image](https://user-images.githubusercontent.com/53981601/133567064-cd29a7d5-7bba-4259-b060-c0ce1c1d10e2.png)

Podemos ver como se puede ejecutar desde el browser
![image](https://user-images.githubusercontent.com/65041178/133100101-c15f0097-9687-4b2b-b431-a6a4f0ebc985.png)

![image](https://user-images.githubusercontent.com/65041178/133100348-c702709e-f092-4a1a-b6b6-8e57628b6134.png)

![image](https://user-images.githubusercontent.com/65041178/133100447-1597637f-5524-4a03-ad94-990c20a9e733.png)

También podemos ver los nodos que se estan corriendo con el comando jps

![image](https://user-images.githubusercontent.com/53981601/133572880-0d71b9cf-10f5-4714-9db8-b657b097b69e.png)




## Parte 2:
#### Creamos los directorios HDFS que se neesitan para ejecutar tareas de MapReduce



#### Carga de archivos a la carpeta input:
![image](https://user-images.githubusercontent.com/65041178/133121517-4aee3314-12ff-413d-b104-50e19e7388a2.png)

## Parte 3:

#### Instalación de Spark (1):
![image](https://user-images.githubusercontent.com/65041178/133153072-c106a634-1af7-4097-94fe-0b92de69d8a0.png)

#### WordCount (2):
##### Ejecución normal: 
![image](https://user-images.githubusercontent.com/65041178/133466180-d46b7f41-f007-4c36-88cb-8cece5058dde.png)
![image](https://user-images.githubusercontent.com/65041178/133153247-92bf8f0b-c37a-4f8f-960f-3d57873c0b5b.png)
##### Ejecución modificada ():

## Parte 4:

### Pyspark basics:
![image](https://user-images.githubusercontent.com/65041178/133351761-4a31e612-4360-402b-8dc4-21d4aa4c87c6.png)
![image](https://user-images.githubusercontent.com/65041178/133463000-753e6408-cc3c-4a1e-9e86-2ef3d6af833e.png)
-
![image](https://user-images.githubusercontent.com/65041178/133463067-3605c5bd-879d-4864-8d3b-288a83256b38.png)
-
![image](https://user-images.githubusercontent.com/65041178/133463133-d7f0a965-a867-4040-8805-a0cff57b5e6f.png)
-
![image](https://user-images.githubusercontent.com/65041178/133463213-8c5f0e3b-93b1-431b-9677-b9e0d977f205.png)
-
![image](https://user-images.githubusercontent.com/65041178/133463266-e7fc059f-bb39-4c43-be80-a295341f60cc.png)
-
![image](https://user-images.githubusercontent.com/65041178/133463311-ba78f740-6e4e-4e73-ab84-014079be399e.png)
-
![image](https://user-images.githubusercontent.com/65041178/133463802-461900d9-2640-400e-b36e-aa167f2ac044.png)
-

### Pyspark data analysis:

![image](https://user-images.githubusercontent.com/65041178/133465351-8cdceaff-c565-4d26-9d89-51d21be13a61.png)
-
![image](https://user-images.githubusercontent.com/65041178/133465401-2243b2b5-50f4-48aa-a3f9-bea75ea66a7a.png)
-
![image](https://user-images.githubusercontent.com/65041178/133465479-4dec174b-8550-4747-b593-5a7e4707609b.png)
-
![image](https://user-images.githubusercontent.com/65041178/133465598-c2064c47-38f5-4b52-aaf5-238d3cc361dc.png)
-
![image](https://user-images.githubusercontent.com/65041178/133465664-f14d5edb-7104-422c-b941-585d77360db6.png)
-
![image](https://user-images.githubusercontent.com/65041178/133465701-abf0b752-f0b6-4e55-9545-5c6daf58b489.png)
-
![image](https://user-images.githubusercontent.com/65041178/133466399-c89e91ac-4c90-48a6-9179-e61c2f79c273.png)
